{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Router\n",
    "\n",
    "Reference link: https://docs.llamaindex.ai/en/stable/examples/low_level/router.html\n",
    "\n",
    "To build a router, we’ll walk through the following steps:\n",
    "\n",
    "- Crafting an initial prompt to select a set of choices\n",
    "- Enforcing structured output (for text completion endpoints)\n",
    "- Try integrating with a native function calling endpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv(\"../secrets.env\")) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "LANGCHAIN_API_KEY = os.getenv('LANGCHAIN_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, fields\n",
    "from pydantic import BaseModel, Field, validator\n",
    "import json\n",
    "\n",
    "from langchain_community.utils.openai_functions import (\n",
    "    convert_pydantic_to_openai_function,\n",
    ")\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field, validator\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0, api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = \"\"\"\n",
    "    Eres un router, tu tarea es tomar una decisión entre las siguientes tareas basandote en el mensaje humano:\n",
    "\n",
    "    \"GENERATE\" Toma este camino si el mensaje humano requiere de generar un documento legal.\n",
    "    \"ANALIZE\" Toma este camino si el mensaje humano requiere de analizar un documento legal.\n",
    "    \"OTHER\" Toma este camino si el mensaje humano no coincide con ninguna de las tareas pero se refiere a una tarea legal.\n",
    "    \"INVALID\" Toma este camino si el mensaje humano no tiene que ver con ninguna tarea legal.\n",
    "\n",
    "    Regla 1: Nunca debes inferir información si no aparece en el contexto de la consulta.\n",
    "    Regla 2: Solo puedes responder con el tipo de consulta que elijas basándote en la razón por la que la elijas.\n",
    "\n",
    "    Responde solo con el tipo de consulta que elijas, solo una palabra.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", router_prompt), \n",
    "     (\"user\", \"{input}\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Answer(BaseModel):\n",
    "    task: str = Field(description=\"name of the task\")\n",
    "    reason: str = Field(description=\"reason why it was choosen\")\n",
    "\n",
    "openai_functions = [convert_pydantic_to_openai_function(Answer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model.bind(functions=openai_functions) | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'GENERATE',\n",
       " 'reason': 'El mensaje humano requiere generar un documento legal'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"Genera un contrato de arrendamiento\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'ANALIZE',\n",
       " 'reason': 'El mensaje humano menciona específicamente la tarea de analizar un documento legal.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"Analiza la siguiente demanda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'INVALID',\n",
       " 'reason': 'La consulta no está relacionada con una tarea legal.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"Cuantas horas tiene un mes?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
